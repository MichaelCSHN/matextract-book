{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be0a87e7-7aca-4d7c-8988-441b72071b13",
   "metadata": {},
   "source": [
    "Doing the same with the new OpenAI model \"GPT-4O\" will allow to compare between open and closed-source models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a6c30db",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install -qqq datasets evaluate python-dotenv litellm --progress-bar off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7059e140",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import json \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from datasets import (\n",
    "    load_dataset,\n",
    ")\n",
    "import litellm\n",
    "from litellm import completion\n",
    "from litellm.caching import Cache\n",
    "from evaluate import load\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcfa8c46",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "litellm.cache = Cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7db287b5",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\".env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bad7850-dc12-4cfd-8c71-338c95895f06",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "OpenAI models are also supported by the *LiteLLM* package.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41f62cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff034057",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'output'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds_path = \"test.json\"\n",
    "test_dataset = load_dataset(\"json\", data_files=test_ds_path, split=\"train\")\n",
    "test_dataset = test_dataset.shuffle(seed=42)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1573913d",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "PREFIX = \"\"\"You are a helpful scientific assistant. Your task is to extract information about organic reactions. {shot}\"\"\"\n",
    "SUFFIX = \"\"\"\\n\\n{sample}\\n\\n\"\"\"\n",
    "SHOT = \"\"\"\n",
    "One example is provided to you to show how to perform the task:\n",
    "\n",
    "### Procedure:\\nA suspension of 8 g of the product of Example 7 and 0.4 g of DABCO in 90 ml of xylenes were heated under N2 at 130\\u00b0-135\\u00b0 C. while 1.8 ml of phosgene was added portionwise at a rate to maintain a reflux temperature of about 130\\u00b0-135\\u00b0 C. The mixture was refluxed an additional two hours, cooled under N2 to room temperature, filtered, and the filtrate was concentrated in vacuo to yield 6.9 g of the subject compound as a crude oil.\\n\\n\n",
    "### ORD JSON:\\n{\\\"inputs\\\": {\\\"m1_m2_m4\\\": {\\\"components\\\": [{\\\"identifiers\\\": [{\\\"type\\\": \\\"NAME\\\", \\\"value\\\": \\\"product\\\"}], \\\"amount\\\": {\\\"mass\\\": {\\\"value\\\": 8.0, \\\"units\\\": \\\"GRAM\\\"}}, \\\"reaction_role\\\": \\\"REACTANT\\\"}, {\\\"identifiers\\\": [{\\\"type\\\": \\\"NAME\\\", \\\"value\\\": \\\"DABCO\\\"}], \\\"amount\\\": {\\\"mass\\\": {\\\"value\\\": 0.4, \\\"units\\\": \\\"GRAM\\\"}}, \\\"reaction_role\\\": \\\"REACTANT\\\"}, {\\\"identifiers\\\": [{\\\"type\\\": \\\"NAME\\\", \\\"value\\\": \\\"xylenes\\\"}], \\\"amount\\\": {\\\"volume\\\": {\\\"value\\\": 90.0, \\\"units\\\": \\\"MILLILITER\\\"}}, \\\"reaction_role\\\": \\\"SOLVENT\\\"}]}, \\\"m3\\\": {\\\"components\\\": [{\\\"identifiers\\\": [{\\\"type\\\": \\\"NAME\\\", \\\"value\\\": \\\"phosgene\\\"}], \\\"amount\\\": {\\\"volume\\\": {\\\"value\\\": 1.8, \\\"units\\\": \\\"MILLILITER\\\"}}, \\\"reaction_role\\\": \\\"REACTANT\\\"}]}}, \\\"conditions\\\": {\\\"temperature\\\": {\\\"control\\\": {\\\"type\\\": \\\"AMBIENT\\\"}}, \\\"conditions_are_dynamic\\\": true}, \\\"workups\\\": [{\\\"type\\\": \\\"ADDITION\\\", \\\"details\\\": \\\"was added portionwise at a rate\\\"}, {\\\"type\\\": \\\"TEMPERATURE\\\", \\\"details\\\": \\\"to maintain a reflux temperature of about 130\\\\u00b0-135\\\\u00b0 C\\\"}, {\\\"type\\\": \\\"TEMPERATURE\\\", \\\"details\\\": \\\"The mixture was refluxed an additional two hours\\\", \\\"duration\\\": {\\\"value\\\": 2.0, \\\"units\\\": \\\"HOUR\\\"}}, {\\\"type\\\": \\\"FILTRATION\\\", \\\"details\\\": \\\"filtered\\\"}, {\\\"type\\\": \\\"CONCENTRATION\\\", \\\"details\\\": \\\"the filtrate was concentrated in vacuo\\\"}], \\\"outcomes\\\": [{\\\"products\\\": [{\\\"identifiers\\\": [{\\\"type\\\": \\\"NAME\\\", \\\"value\\\": \\\"subject compound\\\"}], \\\"measurements\\\": [{\\\"type\\\": \\\"AMOUNT\\\", \\\"details\\\": \\\"MASS\\\", \\\"amount\\\": {\\\"mass\\\": {\\\"value\\\": 6.9, \\\"units\\\": \\\"GRAM\\\"}}}], \\\"reaction_role\\\": \\\"PRODUCT\\\"}]}]}\n",
    "\\n\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b2b9954-2646-4939-99b5-f5bdfd6c4a36",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "bertscore = load(\"bertscore\")\n",
    "# Generate text\n",
    "results = {}\n",
    "for i in range(2):\n",
    "    predictions = []\n",
    "    references = []\n",
    "    \n",
    "    for t in test_dataset:\n",
    "        instruction = t['instruction']\n",
    "        output = t['output']\n",
    "        if i == 0:\n",
    "            shot = ''\n",
    "        else:\n",
    "            shot = SHOT\n",
    "        system = PREFIX.format(shot=shot)\n",
    "        user = SUFFIX.format(sample=instruction)\n",
    "        prompt = [\n",
    "            {\"role\": \"system\", \"content\": system},\n",
    "            {\"role\": \"user\", \"content\": user}\n",
    "        ]\n",
    "        pred = completion(\n",
    "            model=base_model,\n",
    "            messages=prompt,\n",
    "            caching=True,\n",
    "            temperature=0,\n",
    "        ).choices[0].message.content\n",
    "\n",
    "        if '```json' in pred:\n",
    "             pred = pred.replace(\"```json\\n\", '')\n",
    "             pred = pred.replace(\"```\", '')\n",
    "\n",
    "    # The computing of the metrics should be in a different cell\n",
    "        \n",
    "        references.append(output)\n",
    "        predictions.append(pred)\n",
    "\n",
    "    results[f'{i}-shot'] = {\n",
    "        'predictions': predictions,\n",
    "        'references': references,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb7a9070",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ce47lin/miniconda3/envs/review/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    predictions = results[f'{i}-shot']['predictions']\n",
    "    references = results[f'{i}-shot']['references']\n",
    "\n",
    "    results_ = bertscore.compute(predictions=predictions, references=references, model_type=\"distilbert-base-uncased\")\n",
    "\n",
    "    results[f'{i}-shot'].update({\n",
    "        'precision': mean(results_['precision']),\n",
    "        'recall': mean(results_['recall']),\n",
    "        'f1_scores': mean(results_['f1']),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ca60379-12e0-416b-a03a-cd8e89cb9a21",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "with open('OpenAI_results.json', 'w') as f:\n",
    "   json.dump(results, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
