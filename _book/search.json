[
  {
    "objectID": "constrained_decoding/index.html#defining-a-data-schema",
    "href": "constrained_decoding/index.html#defining-a-data-schema",
    "title": "Constrained generation to guarantee syntactic correctness",
    "section": "",
    "text": "from pydantic import BaseModel\n\nclass Recipe(BaseModel):\n    title: str\n    ingredients: List[str]\n    instructions: List[str]\n\nfrom pydantic import BaseModel, Field\nfrom typing import Literal, List\n\nclass Recipe(BaseModel):\n    title: str\n    ingredients: List[str]\n    instructions: List[str]\n    servings: int = Field(..., gt=0, description=\"The number of servings for this recipe\")\n    rating: Literal[\"easy\", \"medium\", \"hard\"] = Field(\"easy\", description=\"The difficulty level of this recipe\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Constrained generation to guarantee syntactic correctness</span>"
    ]
  },
  {
    "objectID": "ocr/nougat/nougat.html#cleaning-the-data",
    "href": "ocr/nougat/nougat.html#cleaning-the-data",
    "title": "OCR with Nougat",
    "section": "Cleaning the data",
    "text": "Cleaning the data\nFor certain applications it might be necessary to clean the data before using it for other downstream tasks."
  },
  {
    "objectID": "index.html#about-this-book",
    "href": "index.html#about-this-book",
    "title": "Generative structured data extraction using LLMs",
    "section": "About this book",
    "text": "About this book\nStructured data is at the heart of machine learning. LLMs offer a convenient way to generate structured data based on unstructured inputs. This book gives hands-on examples of the different steps in the extraction workflow using LLMs."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Generative structured data extraction using LLMs",
    "section": "",
    "text": "About this book\nStructured data is at the heart of machine learning. LLMs offer a convenient way to generate structured data based on unstructured inputs. This book gives hands-on examples of the different steps in the extraction workflow using LLMs.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Generative structured data extraction using LLMs</span>"
    ]
  },
  {
    "objectID": "constrained_decoding/index.html",
    "href": "constrained_decoding/index.html",
    "title": "Constrained generation to guarantee syntactic correctness",
    "section": "",
    "text": "Defining a data schema\nFor most constrained generation tasks, we need to define a data schema in a programmatic way. The most common way to do so is to use pydantic data classes. Here is an example of a simple data schema for a recipe:\nThis schema can also be extended to include descriptions of different fields or to only allow certain values for specific fields. For example, we could add a field for the number of servings and only allow positive integers.\nIf we want to extract copolymerization reactions a data schema could look like the following.\nWe can now use instructor to “patch” the OpenAI API client to ensure that our output fulfils the schema.\nclient = instructor.patch(OpenAI(), mode=instructor.Mode.MD_JSON)\n\n\nclass Monomer(BaseModel):\n    name: str = Field(..., title=\"Name\", description=\"Name of the monomer.\")\n    reactivity_constant: Optional[float] = Field(\n        None,\n        title=\"Reactivity constant\",\n        description=\"Reactivity constant of the monomer. r1 for monomer 1 and r2 for monomer 2. Must be greater or equal 0.\",\n        ge=0,\n    )\n    reactivity_constant_error: Optional[float] = Field(\n        None,\n        title=\"Reactivity constant error\",\n        description=\"Error in the reactivity constant. Often indicated with +/-. Must be greater or equal 0\",\n        ge=0,\n    )\n    q_parameter: Optional[float] = Field(\n        None,\n        title=\"Q parameter\",\n        description=\"Q parameter of the monomer. Q1 for monomer 1 and Q2 for monomer 2. Must be greater or equal 0\",\n        ge=0,\n    )\n    e_parameter: Optional[float] = Field(\n        None,\n        title=\"e parameter\",\n        description=\"e parameter of the monomer. e1 for monomer 1 and e2 for monomer 2.\",\n    )\n\n\nclass CopolymerizationReaction(BaseModel):\n    temperature: Optional[float] = Field(\n        ...,\n        title=\"Temperature\",\n        description=\"Temperature at which the reaction is carried out\",\n    )\n    temperature_unit: Optional[Literal[\"C\", \"K\"]] = Field(\n        ..., title=\"Temperature unit\", description=\"Unit of temperature\"\n    )\n    solvent: Optional[str] = Field(\n        None,\n        title=\"Solvent\",\n        description=\"Solvent used in the reaction. If bulk polymerization was performed, this field should be left empty\",\n    )\n    initiator: Optional[str] = Field(\n        None, title=\"Initiator\", description=\"Initiator used in the reaction\"\n    )\n    monomers: Optional[List[Monomer]] = Field(\n        ...,\n        title=\"Monomers\",\n        description=\"Monomers used in the reaction. Ensure that the reactivity ratios are not confused with other numbers (such as Q and e). The two monomers MUST be used in the same reaction and mentioned in the same context.\",\n        min_items=2,\n        max_items=2,\n    )\n    polymerization_type: Optional[str] = Field(\n        ...,\n        title=\"Polymerization type\",\n        description=\"Type of polymerization (e.g., bulk, solution, suspension, emulsion)\",\n    )\n    determination_method: Optional[str] = Field(\n        ...,\n        title=\"Determination method\",\n        description=\"Method used to determine the reactivity ratios (e.g. Kelen Tudor, Fineman-Ross, Mayo-Lewis).\",\n    )\ndiagram = erd.create(CopolymerizationReaction)\ndiagram.draw(\"diagram.svg\")\nSVG(\"diagram.svg\")\nIn this case, we will use PDF files in the form as images as input for the model. To perform this conversion, we import some utilities.\nfrom pdf2image import convert_from_path\nfrom utils import process_image, get_prompt_vision_model\nThe code below only converts each page of the PDF into an image and then generates dictionary objects in a format that can be used by the OpenAI API.\nfilepath = 'paper01.pdf'\npdf_images = convert_from_path(filepath)\n\nimages_base64 = [process_image(image, 2048, 'images', filepath, j)[0] for j, image in enumerate(pdf_images)]\nimages = get_prompt_vision_model(images_base64=images_base64)\nArmed with the images, we can now use the OpenAI API to extract the text from the images. For this, we just call the API with our prompts and the images.\ncompletion = client.chat.completions.create(\n    model=\"gpt-4-turbo\",\n    response_model=List[CopolymerizationReaction],\n    max_retries=2,\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": \"\"\"You are a scientific assistant, extracting accurate information about co-polymerization reactions from scientific papers.\nDo not use data that was reproduced from other sources.\nIf you confuse the reactivity ratios with other numbers, you will be penalized.\nMonomer names might be quite similar, if you confuse them, you will be penalized.\nNEVER combine data from different reactions, otherwise you will be penalized.\nIf you are unsure, return no data. Quality is more important than quantity.\n\"\"\",\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"\"\"Extract the data from the paper into the provided data schema. We want an iterable of reaction objects and each reaction will be its own object. You can find each page of the paper as an image below.\nThe relationship between monomers and parameters is typically indicated by subscripts that can be a number or an abbreviation of the monomer.\nNever return data that you are not absolutely sure about! You will be penalized for incorrect data.\"\"\",\n        },\n        {\"role\": \"user\", \"content\": [*images]},\n    ],\n    temperature=0,\n)\ncompletion\n\n[CopolymerizationReaction(temperature=60.0, temperature_unit='C', solvent='carbon tetrachloride', initiator='AIBN', monomers=[Monomer(name='methacrylic acid', reactivity_constant=0.54, reactivity_constant_error=0.01, q_parameter=None, e_parameter=None), Monomer(name='styrene', reactivity_constant=0.06, reactivity_constant_error=0.03, q_parameter=None, e_parameter=None)], polymerization_type='solution', determination_method='Kelen-Tudos'),\n CopolymerizationReaction(temperature=60.0, temperature_unit='C', solvent='chloroform', initiator='AIBN', monomers=[Monomer(name='methacrylic acid', reactivity_constant=0.51, reactivity_constant_error=0.01, q_parameter=None, e_parameter=None), Monomer(name='styrene', reactivity_constant=0.08, reactivity_constant_error=0.03, q_parameter=None, e_parameter=None)], polymerization_type='solution', determination_method='Kelen-Tudos'),\n CopolymerizationReaction(temperature=60.0, temperature_unit='C', solvent='acetone', initiator='AIBN', monomers=[Monomer(name='methacrylic acid', reactivity_constant=0.43, reactivity_constant_error=0.0, q_parameter=None, e_parameter=None), Monomer(name='styrene', reactivity_constant=0.65, reactivity_constant_error=0.02, q_parameter=None, e_parameter=None)], polymerization_type='solution', determination_method='Kelen-Tudos'),\n CopolymerizationReaction(temperature=60.0, temperature_unit='C', solvent='1,4-dioxane', initiator='AIBN', monomers=[Monomer(name='methacrylic acid', reactivity_constant=0.41, reactivity_constant_error=0.02, q_parameter=None, e_parameter=None), Monomer(name='styrene', reactivity_constant=0.59, reactivity_constant_error=0.05, q_parameter=None, e_parameter=None)], polymerization_type='solution', determination_method='Kelen-Tudos'),\n CopolymerizationReaction(temperature=60.0, temperature_unit='C', solvent='acetonitrile', initiator='AIBN', monomers=[Monomer(name='methacrylic acid', reactivity_constant=0.12, reactivity_constant_error=0.0, q_parameter=None, e_parameter=None), Monomer(name='styrene', reactivity_constant=0.29, reactivity_constant_error=0.0, q_parameter=None, e_parameter=None)], polymerization_type='solution', determination_method='Kelen-Tudos')]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Constrained generation to guarantee syntactic correctness</span>"
    ]
  },
  {
    "objectID": "ocr/nougat/nougat.html",
    "href": "ocr/nougat/nougat.html",
    "title": "OCR with Nougat",
    "section": "",
    "text": "Cleaning the data\nFor certain applications it might be necessary to clean the data before using it for other downstream tasks.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>OCR with Nougat</span>"
    ]
  },
  {
    "objectID": "obtaining_data/obtaining_data.html",
    "href": "obtaining_data/obtaining_data.html",
    "title": "How to obtain data",
    "section": "",
    "text": "Obtaining a set of relevant data sources\nAt the start of the data extraction process you have to collect a set of potentially relevant data sources. Therefore, you could collect a dataset manually or use a tool to help automating and speeding up this process. The Crossref API is a very useful tool to collect the metadata of relevant articles. Besides the API there are multiple Python libraries available that make access to the API easier. One of these libraries is crossrefapi. As an example 100 sources including metadata on the topic ‘buchwald-hartwig coupling’ are extracted and saved into a json file.\n\nfrom crossref.restful import Works\nimport json\n\nworks = Works(timeout=60)\n\n# Performing the search for sources on the topic of buchwald-hartwig coupling for 10 papers\nquery_result = works.query(bibliographic='buchwald-hartwig coupling').select('DOI', 'title', 'author', 'type', 'publisher', 'issued').sample(10)\n\nresults = [item for item in query_result]\n\n# Save 100 results including their metadata in a json file\nwith open('buchwald-hartwig_coupling_results.json', 'w') as file:\n    json.dump(results, file)\n    \nprint(results)\n\n[{'DOI': '10.1021/jo061366i.s001', 'issued': {'date-parts': [[None]]}, 'publisher': 'American Chemical Society (ACS)', 'title': ['Synthesis of Cyclic Peptides Constrained with Biarylamine Linkers Using Buchwald-Hartwig C-N Coupling'], 'type': 'component'}, {'DOI': '10.1002/chin.200723250', 'author': [{'given': 'Peter', 'family': 'Kettler', 'sequence': 'first', 'affiliation': []}], 'issued': {'date-parts': [[2007, 5, 16]]}, 'publisher': 'Wiley', 'title': ['Carbon—Nitrogen Coupling and Buchwald—Hartwig Amination'], 'type': 'journal-article'}, {'DOI': '10.1055/s-0039-1690303', 'issued': {'date-parts': [[2019, 10, 18]]}, 'publisher': 'Georg Thieme Verlag KG', 'title': ['Buchwald–Hartwig Coupling of Piperidines with Hetaryl Bromides'], 'type': 'journal-article'}, {'DOI': '10.1002/chin.200704170', 'author': [{'given': 'V.', 'family': 'Balraju', 'sequence': 'first', 'affiliation': []}, {'given': 'Javed', 'family': 'Iqbal', 'sequence': 'additional', 'affiliation': []}], 'issued': {'date-parts': [[2007, 1, 8]]}, 'publisher': 'Wiley', 'title': ['Synthesis of Cyclic Peptides Constrained with Biarylamine Linkers Using Buchwald—Hartwig C—N Coupling.'], 'type': 'journal-article'}, {'DOI': '10.1021/jo702389v.s004', 'issued': {'date-parts': [[None]]}, 'publisher': 'American Chemical Society (ACS)', 'title': ['Synthesis and Electronic Properties of Sterically Demanding N-Arylphenothiazines and Unexpected Buchwald-Hartwig Aminations'], 'type': 'component'}, {'DOI': '10.1002/adma.201705710', 'author': [{'given': 'Yaozu', 'family': 'Liao', 'sequence': 'first', 'affiliation': [{'name': 'State Key Laboratory for Modification of Chemical Fibers and Polymer Materials &amp; College of Materials Science and Engineering Donghua University  Shanghai 201620 China'}]}, {'given': 'Haige', 'family': 'Wang', 'sequence': 'additional', 'affiliation': [{'name': 'State Key Laboratory for Modification of Chemical Fibers and Polymer Materials &amp; College of Materials Science and Engineering Donghua University  Shanghai 201620 China'}]}, {'given': 'Meifang', 'family': 'Zhu', 'sequence': 'additional', 'affiliation': [{'name': 'State Key Laboratory for Modification of Chemical Fibers and Polymer Materials &amp; College of Materials Science and Engineering Donghua University  Shanghai 201620 China'}]}, {'ORCID': 'http://orcid.org/0000-0002-2130-4930', 'authenticated-orcid': False, 'given': 'Arne', 'family': 'Thomas', 'sequence': 'additional', 'affiliation': [{'name': 'Department of Chemistry Functional Materials Technische Universität Berlin  Berlin 10623 Germany'}]}], 'issued': {'date-parts': [[2018, 1, 15]]}, 'publisher': 'Wiley', 'title': ['Efficient Supercapacitor Energy Storage Using Conjugated Microporous Polymer Networks Synthesized from Buchwald–Hartwig Coupling'], 'type': 'journal-article'}, {'DOI': '10.1002/chin.201530214', 'author': [{'given': 'Pallabi', 'family': 'Saikia', 'sequence': 'first', 'affiliation': []}, {'given': 'Gitarthi', 'family': 'Sharma', 'sequence': 'additional', 'affiliation': []}, {'given': 'Sanjib', 'family': 'Gogoi', 'sequence': 'additional', 'affiliation': []}, {'given': 'Romesh C.', 'family': 'Boruah', 'sequence': 'additional', 'affiliation': []}], 'issued': {'date-parts': [[2015, 7]]}, 'publisher': 'Wiley', 'title': ['ChemInform Abstract: Cascade Imination, Buchwald—Hartwig Cross Coupling and Cycloaddition Reaction: Synthesis of Pyrido[2,3‐d]pyrimidines.'], 'type': 'journal-article'}, {'DOI': '10.1016/j.tetlet.2011.02.049', 'author': [{'given': 'Ahlem', 'family': 'Bouhlel', 'sequence': 'first', 'affiliation': []}, {'given': 'Christophe', 'family': 'Curti', 'sequence': 'additional', 'affiliation': []}, {'given': 'Omar', 'family': 'Khoumeri', 'sequence': 'additional', 'affiliation': []}, {'given': 'Patrice', 'family': 'Vanelle', 'sequence': 'additional', 'affiliation': []}], 'issued': {'date-parts': [[2011, 4]]}, 'publisher': 'Elsevier BV', 'title': ['Efficient one-pot double Buchwald–Hartwig coupling reaction on 5-phenyl-4-phenylsulfonyl-2,3-dihydrofuran derivatives'], 'type': 'journal-article'}, {'DOI': '10.1002/chin.201208093', 'author': [{'given': 'Dong‐Hwan', 'family': 'Lee', 'sequence': 'first', 'affiliation': []}, {'given': 'Abu', 'family': 'Taher', 'sequence': 'additional', 'affiliation': []}, {'given': 'Shahin', 'family': 'Hossain', 'sequence': 'additional', 'affiliation': []}, {'given': 'Myung‐Jong', 'family': 'Jin', 'sequence': 'additional', 'affiliation': []}], 'issued': {'date-parts': [[2012, 1, 27]]}, 'publisher': 'Wiley', 'title': ['ChemInform Abstract: An Efficient and General Method for the Heck and Buchwald—Hartwig Coupling Reactions of Aryl Chlorides.'], 'type': 'journal-article'}, {'DOI': '10.1039/c7qi00125h', 'author': [{'given': 'Alexander', 'family': 'Feyrer', 'sequence': 'first', 'affiliation': [{'name': 'Institute of Inorganic Chemistry'}, {'name': 'Karlsruhe Institute of Technology (KIT)'}, {'name': '76131 Karlsruhe'}, {'name': 'Germany'}]}, {'ORCID': 'http://orcid.org/0000-0002-6615-1712', 'authenticated-orcid': False, 'given': 'Frank', 'family': 'Breher', 'sequence': 'additional', 'affiliation': [{'name': 'Institute of Inorganic Chemistry'}, {'name': 'Karlsruhe Institute of Technology (KIT)'}, {'name': '76131 Karlsruhe'}, {'name': 'Germany'}]}], 'issued': {'date-parts': [[2017]]}, 'publisher': 'Royal Society of Chemistry (RSC)', 'title': ['Palladium complexes of ferrocene-based phosphine ligands as redox-switchable catalysts in Buchwald–Hartwig cross-coupling reactions'], 'type': 'journal-article'}]\n\n\n\n\nData mining from an available database\nThere are multiple dataset available which are open for data mining. To download full text documents from open access libararys the paperscraper tool can be used. As an example full text articles from ChemRxiv to the topic of ‘buchwald-hartwig coupling’ were downloaded.\n\nfrom paperscraper.get_dumps import chemrxiv\n\n# Download of the chemrxiv paper dump\nchemrxiv(save_path='chemrxiv_2020-11-10.jsonl')\n\n23763it [1:24:56,  4.66it/s]\n100%|██████████| 23766/23766 [00:07&lt;00:00, 3167.05it/s]\n\n\nINFO:paperscraper.get_dumps.utils.chemrxiv.utils:Done, shutting down\n\n\n\nfrom paperscraper.xrxiv.xrxiv_query import XRXivQuery\nfrom paperscraper.pdf import save_pdf_from_dump\nimport pandas as pd\n\ndf = pd.read_json('./chemrxiv_2020-11-10.jsonl', lines=True)\n\n# define keywords for the paper search\nsynthesis = ['synthesis']\nreaction = ['buchwald-hartwig']\n\n# combine keywords \nquery = [synthesis, reaction]\n\n# start searching for relevent papaers in the chemrxiv dump\nquerier = XRXivQuery('./chemrxiv_2020-11-10.jsonl')\nquerier.search_keywords(query, output_filepath='buchwald-hartwig_coupling_ChemRxiv.jsonl')\n\n# Save PDFs in current folder and name the files by their DOI\nsave_pdf_from_dump('./buchwald-hartwig_coupling_ChemRxiv.jsonl', pdf_path='./PDFs', key_to_save='doi')\n\nProcessing paper 5/5: 100%|██████████| 5/5 [00:07&lt;00:00,  1.55s/it]\n\n\n\n\nData annotation\nTo annotate data tools like doccano can help to speed up the process. To use the doccano tool at first a database and account has to be created.\n\n#initialize the database \n$ doccano init\n$ doccano createuser --username admin --password pass\n$ doccano webserver --port 8000\n\n#start the annotation task\n$ doccano task\n\nAfterwards one can access the created database, login with the created account and upload the unannotated articles there. After that one can start annotating the dataset with adding relevant labels to the text of the articles.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>How to obtain data</span>"
    ]
  }
]