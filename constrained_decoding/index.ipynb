{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constrained generation to guarantee syntactic correctness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note title=\"Motivation\"}\n",
    "If we want to generate output that is structured in a specific way, we can use various techniques to \n",
    "\n",
    "- make the extraction more efficient (but automatically adding the \"obvious\" tokens)\n",
    "- make the generation guaranteed to be syntactically correct\n",
    "- make the generation sometimes more semantically correct, too \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enable constrained decoding, we will use one of the most popular packages for this task [`instructor`](https://jxnl.github.io/instructor/).\n",
    "It is built on [`pydantic`]() and can leverage function calling and JSON-mode of the OpenAI API as well as other constrained sampling approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Literal\n",
    "\n",
    "import instructor\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env', override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a data schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most constrained generation tasks, we need to define a data schema in a programmatic way.\n",
    "The most common way to do so is to use `pydantic` data classes.\n",
    "Here is an example of a simple data schema for a recipe:\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    title: str\n",
    "    ingredients: List[str]\n",
    "    instructions: List[str]\n",
    "```\n",
    "\n",
    "This schema can also be extended to include descriptions of different fields or to only allow certain values for specific fields. For example, we could add a field for the number of servings and only allow positive integers.\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal, List\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    title: str\n",
    "    ingredients: List[str]\n",
    "    instructions: List[str]\n",
    "    servings: int = Field(..., gt=0, description=\"The number of servings for this recipe\")\n",
    "    rating: Literal[\"easy\", \"medium\", \"hard\"] = Field(\"easy\", description=\"The difficulty level of this recipe\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to extract copolymerization reactions a data schema could look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CopolymerizationReaction(BaseModel):\n",
    "    temperature: float = Field(..., title=\"Temperature\", description=\"Temperature at which the reaction is carried out\")\n",
    "    temperature_unit: Literal[\"C\", \"K\"] = Field(..., title=\"Temperature unit\", description=\"Unit of temperature\")\n",
    "    solvent: Optional[str] = Field(None, title=\"Solvent\", description=\"Solvent used in the reaction. If bulk polymerization was performed, this field should be left empty\")\n",
    "    initiator: Optional[str] = Field(None, title=\"Initiator\", description=\"Initiator used in the reaction\")\n",
    "    monomers: List[str] = Field(..., title=\"Monomers\", description=\"Names of the monomers used in the reaction\", min_items=2, max_items=2)\n",
    "    reactivity_ratios: List[float] = Field(..., title=\"Reactivity ratios\", description=\"Reactivity ratios of the monomers\", min_items=2, max_items=2)\n",
    "    reactivity_ratios_confidence_intervals: List[float] = Field(..., title=\"Reactivity ratios confidence intervals\", description=\"Estimated error for the reactivity ratios of the monomers\", min_items=2, max_items=2)\n",
    "    polymerization_type: str = Field(..., title=\"Polymerization type\", description=\"Type of polymerization (e.g. free radical, anionic, cationic)\")\n",
    "    determination_method: str = Field(..., title=\"Determination method\", description=\"Method used to determine the reactivity ratios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this schema, we can now use `instructor` to \"patch\" the OpenAI API client to ensure that our output fulfils the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = instructor.patch(\n",
    "    OpenAI(), mode=instructor.Mode.MD_JSON\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we will use PDF files in the form as images as input for the model. To perform this conversion, we import some utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from utils import process_image, get_prompt_vision_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'example.pdf'\n",
    "pdf_images = convert_from_path(filepath)\n",
    "\n",
    "images_base64 = [process_image(image, 2048, 'images', filepath, j)[0] for j, image in enumerate(pdf_images)]\n",
    "images = get_prompt_vision_model(images_base64=images_base64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4-vision-preview\",\n",
    "    response_model=List[CopolymerizationReaction],\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"You are a scientific assistant, extracting important information about polymerization conditions.\n",
    "Extract only data which you are 100% confident about. If you are unsure about any information (e.g. because it is not legible), please leave it blank.\n",
    "We must ensure that the data is accurate and reliable.\"\"\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": [*images]},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "structdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
